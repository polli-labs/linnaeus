MODEL:
  TYPE: "mFormerV0"
  NAME: "mFormerV0_sm"

  DROP_RATE: 0.1 # General dropout for projection layers and MLP (drop connect)
  DROP_PATH_RATE: 0.2 # Stochastic depth for transformer blocks. Randomly drops entire layers during training, with deeper layers dropped more frequently
  ATTN_DROP_RATE: 0.1 #  Applied to attention weights in the self-attention mechanism
  LABEL_SMOOTHING: 0.1

  ONLY_LAST_CLS: false

  # Set EXTRA_TOKEN_NUM to 1 (class token) + number of metadata components
  # We have 3 components: TEMPORAL (2), SPATIAL (3), and ELEVATION (10)
  # For mFormerV0, this should be the number of components, not their dimensions
  EXTRA_TOKEN_NUM: 4 # 1 class token + 3 metadata components
  
  IN_CHANS: 3

  # -----------------------------------------------------------
  # Convolutional Stages:
  #   S0 => 3-layer stem => out=64
  #   S1 => 2 MBConv blocks => out=96
  #   S2 => 3 MBConv blocks => out=192
  # -----------------------------------------------------------
  CONV_STAGES:
    STEM_OUT: 64          # final out-chans of the stem
    EMBED_DIMS:   [64,  96]    # stage1 in/out: 64→96
    OUT_CHANNELS: [96, 192]    # stage2 in/out: 96→192
    DEPTHS:       [2,   3]     # stage1 => 2 blocks, stage2 => 3 blocks
    #
    # stage1 => 2 blocks => [1,1] (no further downsample)
    # stage2 => 3 blocks => [1,1,1]
    #
    STRIDE_SEQS:
      - [2, 1]
      - [1, 1, 1]

  # -----------------------------------------------------------
  # Attention Stages:
  #   S3 => 5 Transformer blocks => embed=384
  #   S4 => 2 Transformer blocks => embed=768
  # -----------------------------------------------------------
  ATTENTION_STAGES:
    EMBED_DIMS: [384, 768]
    DEPTHS: [5, 2]
    NUM_HEADS: [8, 8]
    MLP_RATIO: [4.0, 4.0]
    ATTENTION_TYPE: ["RelativeAttention", "RelativeAttention"]
    #
    # stage3 => 5 blocks => first block has stride=2 for downsampling
    # stage4 => 2 blocks => first block has stride=2 for downsampling
    #
    STRIDE_SEQS:
      - [2, 1, 1, 1, 1]  # stage3: downsample at first block
      - [2, 1]           # stage4: downsample at first block

  AGGREGATION:
    TYPE: "Conv1d"
    PARAMETERS:
      in_channels: 768
      out_channels: 768
      kernel_size: 2
      bias: true

  CLASSIFICATION:
    HEADS: {}

  NORMALIZATION:
    CONV_NORM_LAYER: "BatchNorm2d"
    ATTENTION_NORM_LAYER: "LayerNorm"
    ACTIVATION_LAYER: "ReLU"
