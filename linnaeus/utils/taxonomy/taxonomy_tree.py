# linnaeus/utils/taxonomy/taxonomy_tree.py
"""
Centralized representation and utility class for taxonomic hierarchies.

This module provides the TaxonomyTree class, which parses the hierarchy_map
generated during dataset processing and offers a consistent API for querying
taxonomic relationships, distances, and structures needed by various components
like taxonomy-aware label smoothing and hierarchical classification heads.
It also supports saving its essential state to a JSON file and loading from it.
"""

import json
import logging
import os
from collections import deque
from typing import Any

import torch

from linnaeus.utils.logging.logger import get_main_logger

logger = get_main_logger()

# Type alias for clarity: (task_key_string, class_index_int)
Node = tuple[str, int]


class TaxonomyTree:
    """
    Represents the taxonomic hierarchy as a tree (or forest).

    Parses the specific `hierarchy_map` structure generated by
    `vectorized_dataset_processor.py` (Dict[child_task_key, Dict[child_idx, parent_idx]])
    into an internal bidirectional graph representation. Provides methods for
    traversal, distance calculation, validation, and generating helper structures
    for downstream components.

    Supports saving to and loading from a single JSON asset file.

    Attributes:
        task_keys (List[str]): Ordered list of task keys representing hierarchy levels.
        num_classes (Dict[str, int]): Number of classes at each task level.
        roots (List[Node]): List of root nodes (nodes without parents in the provided map).
        leaves (List[Node]): List of leaf nodes (nodes without children in the provided map).
        # Future Metaclade Attributes (Placeholder)
        # is_multi_rooted (bool): True if derived from multiple distinct roots above task_keys.
        # true_biological_roots (List[Tuple[str, int]]): IDs of the highest ancestors found.
        # node_to_true_root (Dict[Node, Tuple[str, int]]): Mapping nodes to their ultimate root.
    """

    def __init__(
        self,
        hierarchy_map: dict[str, dict[Any, Any]],  # Allow Any for keys/values initially
        task_keys: list[str],
        num_classes: dict[str, int],
        # --- Future Metaclade Args ---
        # is_multi_rooted: bool = False,
        # true_biological_roots: Optional[List[Tuple[str, int]]] = None,
        # node_to_true_root: Optional[Dict[Node, Tuple[str, int]]] = None,
    ):
        """
        Initializes the TaxonomyTree from the hierarchy map.

        Args:
            hierarchy_map: The map generated by `vectorized_dataset_processor.py`.
                           Structure: Dict[child_task_key, Dict[child_class_idx, parent_class_idx]]
                           Keys/values in inner dict might be strings initially.
            task_keys: Ordered list of task keys (e.g., ["taxa_L10", "taxa_L20", ...]).
            num_classes: Dictionary mapping task_key to the number of classes at that level.
            # is_multi_rooted: Flag indicating if the hierarchy is a forest (metaclade).
            # true_biological_roots: List of the actual highest-level root nodes found.
            # node_to_true_root: Mapping from any node to its ultimate root.

        Raises:
            ValueError: If the hierarchy map implies multiple parents for a node or contains cycles.
            KeyError: If task keys in hierarchy_map don't align with task_keys list or num_classes.
        """
        self.task_keys = task_keys
        self.num_classes = num_classes
        # Store raw map, ensuring inner keys/values are integers for consistency during build
        self._hierarchy_map_raw = self._sanitize_raw_map(hierarchy_map)

        # Internal graph representation
        self._parent_to_children: dict[Node, list[Node]] = {}
        self._child_to_parent: dict[Node, Node | None] = {}
        self._nodes_by_level: dict[str, list[Node]] = {}
        self._all_nodes: set[Node] = set()

        # --- Future Metaclade Attributes ---
        # self.is_multi_rooted = is_multi_rooted
        # self.true_biological_roots = true_biological_roots if true_biological_roots else []
        # self.node_to_true_root = node_to_true_root if node_to_true_root else {}
        # --- End Future Metaclade ---

        logger.info("Initializing TaxonomyTree...")
        self._build_internal_graph()

        # Pre-compute roots and leaves based on the provided hierarchy levels
        self.roots: list[Node] = self._find_roots()
        self.leaves: list[Node] = self._find_leaves()

        # Group nodes by level for convenience
        for task in self.task_keys:
            if task in self.num_classes:
                self._nodes_by_level[task] = [
                    (task, idx) for idx in range(self.num_classes[task])
                ]
            else:
                logger.warning(
                    f"Task key '{task}' not found in num_classes during node grouping."
                )

        logger.info(
            f"TaxonomyTree built. Found {len(self.roots)} root nodes (relative to map) "
            f"and {len(self.leaves)} leaf nodes."
        )
        # if self.is_multi_rooted: logger.info(f"Detected metaclade/forest structure with {len(self.true_biological_roots)} true roots.")

        # Validate the constructed tree/forest
        self._validate()
        logger.info("TaxonomyTree validation successful.")

    def _sanitize_raw_map(
        self, raw_map: dict[str, dict[Any, Any]]
    ) -> dict[str, dict[int, int]]:
        """Converts inner keys/values of the raw hierarchy map to integers."""
        sanitized_map = {}
        for child_task_key, level_map in raw_map.items():
            sanitized_level_map = {}
            if not isinstance(level_map, dict):
                logger.warning(
                    f"Expected dict for level '{child_task_key}' in hierarchy_map, got {type(level_map)}. Skipping."
                )
                continue
            for child_idx_raw, parent_idx_raw in level_map.items():
                try:
                    child_idx = int(child_idx_raw)
                    parent_idx = int(parent_idx_raw)
                    sanitized_level_map[child_idx] = parent_idx
                except (ValueError, TypeError):
                    logger.warning(
                        f"Skipping non-integer index pair ({child_idx_raw}, {parent_idx_raw}) "
                        f"in hierarchy map for level {child_task_key}."
                    )
            sanitized_map[child_task_key] = sanitized_level_map
        return sanitized_map

    def _build_internal_graph(self):
        """Parses the sanitized _hierarchy_map_raw into bidirectional graph structures."""
        # 1. Initialize all potential nodes based on num_classes
        for task in self.task_keys:
            n_cls = self.num_classes.get(task)
            if n_cls is None:
                raise KeyError(
                    f"Task key '{task}' from task_keys not found in num_classes."
                )
            for idx in range(n_cls):
                node: Node = (task, idx)
                self._all_nodes.add(node)
                self._parent_to_children[node] = []
                self._child_to_parent[node] = None  # Assume no parent initially

        # 2. Process sanitized hierarchy_map to establish parent-child links BETWEEN levels
        num_links_processed = 0
        for i in range(len(self.task_keys) - 1):
            child_task = self.task_keys[i]
            parent_task = self.task_keys[i + 1]

            level_map = self._hierarchy_map_raw.get(child_task, {})
            if not level_map:
                # logger.debug(f"No hierarchy links found from {child_task} to {parent_task}.")
                continue

            num_level_links = 0
            for child_idx, parent_idx in level_map.items():
                # Indices are already int due to _sanitize_raw_map

                # --- Validation during parsing ---
                if not (0 <= child_idx < self.num_classes[child_task]):
                    logger.warning(
                        f"Child index {child_idx} out of bounds for task {child_task} "
                        f"(max={self.num_classes[child_task] - 1}). Skipping link."
                    )
                    continue
                if not (0 <= parent_idx < self.num_classes[parent_task]):
                    logger.warning(
                        f"Parent index {parent_idx} out of bounds for task {parent_task} "
                        f"(max={self.num_classes[parent_task] - 1}). Skipping link."
                    )
                    continue
                # --- End Validation ---

                child_node: Node = (child_task, child_idx)
                parent_node: Node = (parent_task, parent_idx)

                # Check for multi-parent error
                existing_parent = self._child_to_parent.get(child_node)
                if existing_parent is not None and existing_parent != parent_node:
                    # Log clearly which parents are conflicting
                    logger.error(
                        f"Hierarchy Error: Node {child_node} has multiple parents assigned: "
                        f"{existing_parent} and {parent_node}. This indicates an issue in the "
                        f"source data or hierarchy_map generation. Using the first encountered parent: {existing_parent}."
                    )
                    # Keep the first parent encountered, but log error
                    continue  # Skip adding the conflicting link

                # Add links to internal graph only if not already set (first parent wins)
                if existing_parent is None:
                    self._parent_to_children.setdefault(parent_node, []).append(
                        child_node
                    )  # Use setdefault for parent
                    self._child_to_parent[child_node] = parent_node
                    num_level_links += 1

            # logger.info(f"Processed {num_level_links} hierarchy links from {child_task} to {parent_task}.")
            num_links_processed += num_level_links

        # logger.info(f"Total hierarchy links processed: {num_links_processed}.") # Reduce log noise

    def _validate(self):
        white_set = self._all_nodes.copy()
        gray_set = set()
        black_set = set()
        errors = []

        def detect_cycle_util(node: Node):
            # Move node from white to gray
            white_set.discard(node)
            gray_set.add(node)

            # Explore neighbors (children in a directed hierarchy)
            # NOTE: We only need to check children for DAG cycles.
            #       Checking parents is redundant if the single-parent rule holds.
            for child in self._parent_to_children.get(node, []):
                if child in gray_set:
                    # Found a back edge to a node currently in recursion stack -> CYCLE!
                    errors.append(f"Cycle Detected: Back edge from {node} to {child}")
                    return True  # Cycle found
                if child in white_set:  # If child hasn't been visited at all yet
                    if detect_cycle_util(child):
                        return True  # Cycle found deeper

            # Move node from gray to black, exploration complete
            gray_set.remove(node)
            black_set.add(node)
            return False  # No cycle found from this node

        # Iterate through all nodes to handle disconnected components (forests)
        # Make a copy as we modify white_set during iteration
        nodes_to_process = list(white_set)
        for node in nodes_to_process:
            if node in white_set:  # Only start DFS if node hasn't been visited
                if detect_cycle_util(node):
                    # Cycle found and error added, maybe stop early?
                    # For thoroughness, we could continue checking other components
                    pass  # Error already logged in helper

        # Single Parent check (still relies on checks in _build_internal_graph)
        # Re-iterate here for explicit validation report if needed

        if errors:
            logger.error(f"Hierarchy validation FAILED with {len(errors)} issues:")
            for err in errors[:10]:  # Log first few errors
                logger.error(f"  - {err}")
            if len(errors) > 10:
                logger.error(f"  ... and {len(errors) - 10} more.")
            # Raise the first error to halt execution
            raise ValueError(errors[0])
        else:
            logger.info("Hierarchy validation checks passed (cycles, single parent).")
            return True

    def _find_roots(self) -> list[Node]:
        """Identifies root nodes (nodes with no parent in the map)."""
        # Roots are nodes present in _child_to_parent map with a value of None
        return sorted(
            [node for node, parent in self._child_to_parent.items() if parent is None],
            key=lambda x: (self.task_keys.index(x[0]), x[1]),
        )

    def _find_leaves(self) -> list[Node]:
        """Identifies leaf nodes (nodes with no children in the map)."""
        # Leaves are nodes present in _parent_to_children map with an empty list value
        return sorted(
            [
                node
                for node, children in self._parent_to_children.items()
                if not children
            ],
            key=lambda x: (self.task_keys.index(x[0]), x[1]),
        )

    # --- Public API Methods (Unchanged from previous implementation) ---
    def get_parent(self, child_node: Node) -> Node | None:
        return self._child_to_parent.get(child_node)

    def get_children(self, parent_node: Node) -> list[Node]:
        return self._parent_to_children.get(parent_node, [])

    def get_ancestors(self, node: Node) -> list[Node]:
        if node not in self._child_to_parent:
            return []
        ancestors = [node]
        current = node
        while (parent := self.get_parent(current)) is not None:
            ancestors.append(parent)
            current = parent
        return ancestors  # Ordered [node, parent, grandparent, ...]

    def get_descendants(self, node: Node) -> list[Node]:
        if node not in self._parent_to_children:
            return []
        descendants = []
        queue = deque([node])
        visited = set()
        while queue:
            current = queue.popleft()
            if current in visited:
                continue
            visited.add(current)
            descendants.append(current)
            for child in self.get_children(current):
                if child not in visited:
                    queue.append(child)
        return descendants

    def get_nodes_at_level(self, task_key: str) -> list[Node]:
        return self._nodes_by_level.get(task_key, [])

    def get_root_nodes(self) -> list[Node]:
        return self.roots

    def get_leaf_nodes(self) -> list[Node]:
        return self.leaves

    def _find_lca_and_distances(
        self, node1: Node, node2: Node
    ) -> tuple[Node | None, int, int]:
        if node1 == node2:
            return node1, 0, 0
        ancestors1 = self.get_ancestors(node1)
        ancestors2 = self.get_ancestors(node2)
        if not ancestors1 or not ancestors2:
            return None, -1, -1
        set1 = set(ancestors1)
        lca = None
        dist1 = -1
        dist2 = -1
        for i, ancestor2 in enumerate(ancestors2):
            if ancestor2 in set1:
                lca = ancestor2
                dist2 = i
                dist1 = ancestors1.index(lca)
                break
        return lca, dist1, dist2

    def taxonomic_distance(self, node1: Node, node2: Node) -> float:
        lca, dist1, dist2 = self._find_lca_and_distances(node1, node2)
        if lca is None:
            return float("inf")
        return float(dist1 + dist2)

    @torch.no_grad()
    def build_distance_matrix(self, task_key: str) -> torch.Tensor:
        if task_key not in self.num_classes:
            raise KeyError(f"Task key '{task_key}' not found in num_classes.")
        n_classes = self.num_classes[task_key]
        nodes_at_level = self.get_nodes_at_level(task_key)
        dist_matrix = torch.full(
            (n_classes, n_classes), float("inf"), dtype=torch.float32
        )
        for i in range(n_classes):
            dist_matrix[i, i] = 0.0
            node_i = nodes_at_level[i]
            for j in range(i + 1, n_classes):
                node_j = nodes_at_level[j]
                distance = self.taxonomic_distance(node_i, node_j)
                dist_matrix[i, j] = distance
                dist_matrix[j, i] = distance
        return dist_matrix

    @torch.no_grad()
    def build_hierarchy_matrices(self) -> dict[str, torch.Tensor]:
        hierarchy_matrices = {}
        for i in range(len(self.task_keys) - 1):
            child_task = self.task_keys[i]
            parent_task = self.task_keys[i + 1]
            pair_key = f"{parent_task}_{child_task}"
            num_parent_classes = self.num_classes[parent_task]
            num_child_classes = self.num_classes[child_task]
            matrix = torch.zeros(
                (num_parent_classes, num_child_classes), dtype=torch.float32
            )
            for child_idx in range(num_child_classes):
                child_node = (child_task, child_idx)
                parent_node = self.get_parent(child_node)
                if parent_node and parent_node[0] == parent_task:
                    parent_idx = parent_node[1]
                    if 0 <= parent_idx < num_parent_classes:
                        matrix[parent_idx, child_idx] = 1.0
            hierarchy_matrices[pair_key] = matrix
            # logger.debug(f"Built hierarchy matrix for {pair_key} with shape {matrix.shape}") # Reduce log noise
        return hierarchy_matrices

    # --- Serialization Methods ---

    def save(self, filepath: str):
        """
        Saves the essential data needed to reconstruct the TaxonomyTree to a JSON file.

        Args:
            filepath: The path to the JSON file to save.
        """
        logger.info(f"Saving TaxonomyTree state to {filepath}...")
        try:
            # Prepare data for saving
            data_to_save = {
                "__taxonomy_tree_version__": "1.0",  # Versioning for future changes
                "task_keys": self.task_keys,
                "num_classes": self.num_classes,
                "hierarchy_map_raw": self._hierarchy_map_raw,
                # --- Future Metaclade Data ---
                # "is_multi_rooted": getattr(self, 'is_multi_rooted', False),
                # "true_biological_roots": getattr(self, 'true_biological_roots', []),
                # Convert node tuples in node_to_true_root keys/values if saving it
                # "node_to_true_root": {str(k): str(v) for k, v in getattr(self, 'node_to_true_root', {}).items()},
                # --- End Future Metaclade ---
                "metadata": {
                    "creation_time": logging.Formatter().formatTime(
                        logging.makeLogRecord({})
                    ),
                    # Add other useful metadata if needed
                },
            }

            # Ensure directory exists
            os.makedirs(os.path.dirname(filepath), exist_ok=True)

            with open(filepath, "w") as f:
                json.dump(data_to_save, f, indent=2)
            logger.info("Successfully saved TaxonomyTree state.")

        except TypeError as e:
            logger.error(
                f"Serialization Error: Could not serialize TaxonomyTree state to JSON. "
                f"Check data types. Error: {e}",
                exc_info=True,
            )
            raise
        except OSError as e:
            logger.error(
                f"IO Error: Could not write TaxonomyTree state to file {filepath}. Error: {e}",
                exc_info=True,
            )
            raise
        except Exception as e:
            logger.error(
                f"Unexpected error saving TaxonomyTree state: {e}", exc_info=True
            )
            raise

    @classmethod
    def load(cls, filepath: str) -> "TaxonomyTree":
        """
        Loads the TaxonomyTree state from a JSON file.

        Args:
            filepath: The path to the JSON file to load.

        Returns:
            An initialized TaxonomyTree instance.

        Raises:
            FileNotFoundError: If the file does not exist.
            ValueError: If the file content is invalid or incompatible.
            KeyError: If essential keys are missing in the loaded data.
        """
        logger.info(f"Loading TaxonomyTree state from {filepath}...")
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"TaxonomyTree file not found: {filepath}")

        try:
            with open(filepath) as f:
                data = json.load(f)

            # Basic validation of loaded data
            required_keys = ["task_keys", "num_classes", "hierarchy_map_raw"]
            if not all(key in data for key in required_keys):
                missing = [key for key in required_keys if key not in data]
                raise ValueError(
                    f"Invalid TaxonomyTree file: Missing required keys: {missing}"
                )

            version = data.get("__taxonomy_tree_version__", "0.0")
            if version != "1.0":
                logger.warning(
                    f"Loading TaxonomyTree from an older or unknown version ('{version}'). "
                    f"Compatibility not guaranteed."
                )

            # Extract necessary components
            task_keys = data["task_keys"]
            num_classes = data["num_classes"]
            # The raw map needs sanitization (string keys/values to int) - handled in __init__
            hierarchy_map_raw = data["hierarchy_map_raw"]

            # --- Future Metaclade Loading ---
            # is_multi_rooted = data.get("is_multi_rooted", False)
            # true_biological_roots = data.get("true_biological_roots", [])
            # node_to_true_root_str = data.get("node_to_true_root", {})
            # # Need to parse node_to_true_root keys/values back to tuples
            # node_to_true_root = {eval(k): eval(v) for k, v in node_to_true_root_str.items()}
            # --- End Future Metaclade ---

            # Instantiate the class using the loaded data
            instance = cls(
                hierarchy_map=hierarchy_map_raw,
                task_keys=task_keys,
                num_classes=num_classes,
                # is_multi_rooted=is_multi_rooted, # Pass loaded metaclade info
                # true_biological_roots=true_biological_roots,
                # node_to_true_root=node_to_true_root,
            )
            logger.info(
                f"Successfully loaded and initialized TaxonomyTree from {filepath}."
            )
            return instance

        except json.JSONDecodeError as e:
            logger.error(
                f"JSON Decode Error: Could not parse TaxonomyTree file {filepath}. Error: {e}",
                exc_info=True,
            )
            raise ValueError(f"Invalid JSON format in {filepath}") from e
        except (KeyError, ValueError, TypeError) as e:
            logger.error(
                f"Data Error: Invalid or missing data in TaxonomyTree file {filepath}. Error: {e}",
                exc_info=True,
            )
            raise ValueError(f"Invalid data format in {filepath}") from e
        except Exception as e:
            logger.error(
                f"Unexpected error loading TaxonomyTree state: {e}", exc_info=True
            )
            raise
